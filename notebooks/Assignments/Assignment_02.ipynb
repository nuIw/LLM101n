{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d8158dfddb2ac72",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "In this assignment, you will continue with the Bigram Language Model from the Lecture. Make the training loop and inference for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011cbf15834af26",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Set the random seed for reproducibility.\n",
    "\n",
    "    Args:\n",
    "        seed (int): The seed value to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Random seed set to {seed}\")\n",
    "\n",
    "\n",
    "def configure_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Configure the device for training.\n",
    "\n",
    "    Returns:\n",
    "        torch.device: The device to use for training.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        print(f\"Running on {num_gpu} {torch.cuda.get_device_name()} GPU(s)\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(f\"Running on {device}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(f\"Running on {device}\")\n",
    "    return device\n",
    "\n",
    "\n",
    "def load_text(file_path: str, encoding: str = 'utf-8') -> str:\n",
    "    \"\"\"\n",
    "    Load and read text data from a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the text file.\n",
    "        encoding (str, optional): File encoding. Defaults to 'utf-8'.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the text file.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding) as f:\n",
    "        text = f.read()\n",
    "\n",
    "    print(f\"Loaded text data from {file_path} (length: {len(text)} characters).\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a0b5274f4dca2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef1253f6800c36c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BigramConfig:\n",
    "    root_dir: str = os.getcwd() + \"/../../\"\n",
    "    dataset_path: str = \"data/names.txt\"\n",
    "\n",
    "    # Tokenizer\n",
    "    vocab_size: int = 0  # Set later\n",
    "\n",
    "    seed: int = 101\n",
    "    \n",
    "config = BigramConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726a09b7e375389",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4d38445588cdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 101\n"
     ]
    }
   ],
   "source": [
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74be7e01434a14b",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e86ea6f15f11b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text data from /mnt/c/Users/whald/LLM101n/notebooks/Assignments/../../data/names.txt (length: 228145 characters).\n"
     ]
    }
   ],
   "source": [
    "names = load_text(config.root_dir + config.dataset_path).splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aff6f7e1bbade4",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed24c0db0ce9da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add special token\n",
    "names = [\".\" + name + \".\" for name in names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e38655c11342dd",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2f768e619dfb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [chr(i) for i in range(97, 123)]  # all alphabet characters\n",
    "chars.insert(0, \".\")  # Add special token\n",
    "config.vocab_size = len(chars)\n",
    "str2idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx2str = {idx: char for char, idx in str2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4e1dda633584d",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "523dd8edb6b3e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "W = torch.randn(config.vocab_size, config.vocab_size, requires_grad=True)\n",
    "b = torch.randn(config.vocab_size, requires_grad=True)\n",
    "params = [W, b]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ca7979aafb68a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6125c93c9c7519",
   "metadata": {},
   "source": [
    "#### Task 1: Train Bigram Language Model (Neural Network Approach)\n",
    "\n",
    "Make the training loop for the Bigram Language Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8f5165e72e37f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of Input, Target pairs\n",
    "inputs, targets = [], []\n",
    "for name in names:\n",
    "    for char1, char2 in zip(name, name[1:]):\n",
    "        input = str2idx[char1]\n",
    "        target = str2idx[char2]\n",
    "        inputs.append(input)\n",
    "        targets.append(target)\n",
    "\n",
    "# Convert to tensor\n",
    "inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "targets = torch.tensor(targets, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe57ba03f098d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Input, Target pairs: 228146\n",
      "Input shape: torch.Size([228146])\n",
      "Target shape: torch.Size([228146])\n",
      "First (Input, Target): (0, 5)\n",
      "Second (Input, Target): (5, 13)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Input, Target pairs: {len(inputs)}\")\n",
    "print(f\"Input shape: {inputs.shape}\")\n",
    "print(f\"Target shape: {targets.shape}\")\n",
    "print(f\"First (Input, Target): ({inputs[0]}, {targets[0]})\")\n",
    "print(f\"Second (Input, Target): ({inputs[1]}, {targets[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4baab50fd5515e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# One-hot encode the input tensor.                                             #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "inputs_encoded = F.one_hot(inputs, num_classes = config.vocab_size)\n",
    "targets_encoded = F.one_hot(targets, num_classes = config.vocab_size)\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# Convert data type to float\n",
    "inputs_encoded = inputs_encoded.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a5ef07b0b820e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10, Loss 3.7275\n",
      "Step 20, Loss 3.3789\n",
      "Step 30, Loss 3.2139\n",
      "Step 40, Loss 3.1160\n",
      "Step 50, Loss 3.0472\n",
      "Step 60, Loss 2.9946\n",
      "Step 70, Loss 2.9523\n",
      "Step 80, Loss 2.9172\n",
      "Step 90, Loss 2.8873\n",
      "Step 100, Loss 2.8613\n",
      "Step 110, Loss 2.8385\n",
      "Step 120, Loss 2.8181\n",
      "Step 130, Loss 2.7999\n",
      "Step 140, Loss 2.7833\n",
      "Step 150, Loss 2.7683\n",
      "Step 160, Loss 2.7546\n",
      "Step 170, Loss 2.7419\n",
      "Step 180, Loss 2.7303\n",
      "Step 190, Loss 2.7195\n",
      "Step 200, Loss 2.7094\n",
      "Step 210, Loss 2.7001\n",
      "Step 220, Loss 2.6914\n",
      "Step 230, Loss 2.6832\n",
      "Step 240, Loss 2.6756\n",
      "Step 250, Loss 2.6684\n",
      "Step 260, Loss 2.6616\n",
      "Step 270, Loss 2.6553\n",
      "Step 280, Loss 2.6493\n",
      "Step 290, Loss 2.6436\n",
      "Step 300, Loss 2.6382\n",
      "Step 310, Loss 2.6331\n",
      "Step 320, Loss 2.6283\n",
      "Step 330, Loss 2.6237\n",
      "Step 340, Loss 2.6193\n",
      "Step 350, Loss 2.6152\n",
      "Step 360, Loss 2.6112\n",
      "Step 370, Loss 2.6074\n",
      "Step 380, Loss 2.6038\n",
      "Step 390, Loss 2.6004\n",
      "Step 400, Loss 2.5971\n",
      "Step 410, Loss 2.5939\n",
      "Step 420, Loss 2.5909\n",
      "Step 430, Loss 2.5880\n",
      "Step 440, Loss 2.5852\n",
      "Step 450, Loss 2.5826\n",
      "Step 460, Loss 2.5800\n",
      "Step 470, Loss 2.5776\n",
      "Step 480, Loss 2.5752\n",
      "Step 490, Loss 2.5729\n",
      "Step 500, Loss 2.5707\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "steps = 500\n",
    "lr = 1 #logscale it.\n",
    "\n",
    "for step in range(1, steps + 1):\n",
    "    # Forward pass\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Implement the forward pass.                                                  #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    logits = inputs_encoded @ W + b\n",
    "    probs = logits.exp()/logits.exp().sum(dim=-1,keepdim=True)\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    # loss\n",
    "    log_probs = torch.log(probs + 1e-9)  # Add small value to prevent log(0)\n",
    "    loss = -log_probs[torch.arange(len(targets)), targets].mean()\n",
    "    \n",
    "    # Backward pass\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Implement the backward pass.                                                 #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    loss.backward()\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    # Update weights\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Update the weights of the model using the gradients.                         #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    with torch.no_grad():\n",
    "        W -= lr*W.grad\n",
    "        b -= lr*b.grad\n",
    "        W.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(f\"Step {step}, Loss {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d956fef0a027963",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786f852b486b92cb",
   "metadata": {},
   "source": [
    "#### Task 2: Generate a Name\n",
    "\n",
    "Create a function to generate a name using the trained Bigram Language Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b31dfacd08b51cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aymienzeta.\n",
      "dhchatisrnearasan.\n",
      "tadeleanion.\n",
      "greeema.\n",
      "mzlymaoshyif.\n"
     ]
    }
   ],
   "source": [
    "# Create a function to generate a name\n",
    "def generate_name():\n",
    "    new_name = []\n",
    "    start_idx = str2idx[\".\"]\n",
    "    \n",
    "    while True:\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # 1. Forward pass                                                              #\n",
    "        # 2. Sample the next token                                                     #\n",
    "        # 3. Decode the token                                                          #\n",
    "        # 4. Update the start_idx                                                      #\n",
    "        # 5. Break if the next character is \".\"                                        #\n",
    "        ################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        # Forward pass\n",
    "        start_encode = F.one_hot(torch.tensor([start_idx]),num_classes=config.vocab_size).float()\n",
    "        logits = start_encode@W+b\n",
    "        \n",
    "        # Sample\n",
    "        probs = logits.exp()/logits.exp().sum(dim=-1,keepdim=True)\n",
    "        next_idx = torch.multinomial(probs,num_samples=1).item()\n",
    "        # Decode\n",
    "        next_char = idx2str[next_idx]\n",
    "        new_name.append(next_char)\n",
    "        \n",
    "        # Update\n",
    "        start_idx = next_idx\n",
    "        \n",
    "        # Break if \".\"\n",
    "        if start_idx == str2idx['.']:\n",
    "            break\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    return ''.join(new_name)\n",
    "\n",
    "# Generate 5 names\n",
    "for _ in range(5):\n",
    "    print(generate_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d00faaddbe4b44",
   "metadata": {},
   "source": [
    "## Extra Credit\n",
    "\n",
    "We have already made our own custom auto-grad Tensor class. Let's use it!\n",
    "\n",
    "Train the Bigram Language Model using our custom auto-grad Tensor class.\n",
    "\n",
    "**Do not use any built-in PyTorch functions.** (other deep learning libraries are also prohibited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f26efc1212bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    def __init__(self, data, _children=(), _operation=''):\n",
    "        self.data = data\n",
    "        self._prev = set(_children)\n",
    "        self.gradient = 0\n",
    "        self._backward = lambda: None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"tensor=({self.data})\"\n",
    "\n",
    "    def __add__(self, other):  # self + other\n",
    "        output = Tensor(self.data + other.data, (self, other), '+')\n",
    "        def _backward():\n",
    "            self.gradient = 1 * output.gradient\n",
    "            other.gradient = 1 * output.gradient\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "\n",
    "    def __mul__(self, other):  # self * other\n",
    "        output = Tensor(self.data * other.data, (self, other), '*')\n",
    "        def _backward():\n",
    "            self.gradient = other.data * output.gradient\n",
    "            other.gradient = self.data * output.gradient\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "\n",
    "    def tanh(self):  # tanh(self)\n",
    "        output = Tensor(math.tanh(self.data), (self,), 'tanh')\n",
    "        def _backward():\n",
    "            self.gradient = (1.0 - math.tanh(self.data) ** 2) * output.gradient\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "\n",
    "    def __pow__(self, power):  # self ** power\n",
    "        assert isinstance(power, (int, float)), \"Power must be an int or a float\"\n",
    "        output = Tensor(self.data ** power, (self,), f'**{power}')\n",
    "        def _backward():\n",
    "            self.gradient = power * (self.data ** (power - 1)) * output.gradient\n",
    "        output._backward = _backward\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "        self.gradient = 1\n",
    "        for node in reversed(topo):\n",
    "            node._backward()\n",
    "\n",
    "    def __neg__(self): # -self\n",
    "        return self * Tensor(-1.0)\n",
    "\n",
    "    def __sub__(self, other): # self - other\n",
    "        return self + (-other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7815ada66df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
